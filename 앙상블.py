# -*- coding: utf-8 -*-
"""앙상블.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15PsRuuyFdyrh_ZSzF_8OywT6LoosbakR
"""

import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    accuracy_score, f1_score, confusion_matrix, classification_report,
    roc_auc_score, average_precision_score, roc_curve, auc, precision_recall_curve
)
from sklearn.feature_selection import SelectKBest, mutual_info_classif
from scipy.stats import ttest_ind
from statsmodels.stats.multitest import multipletests
from imblearn.over_sampling import SMOTE

# 1. 모델 및 데이터 로드 함수 (feature selection 포함)
def load_model_and_data(model_type):
    if model_type == 'cnn':
        model = joblib.load("cnn-k-NN_best_model.pkl")
        X_test = joblib.load("cnn_X_test.pkl")
        y_test = joblib.load("cnn_y_test.pkl")
        X_train = joblib.load("cnn_X_train.pkl")
        y_train = joblib.load("cnn_y_train.pkl")

    elif model_type == 'methylation':
        model = joblib.load("methyl_SVM_best_model.pkl")
        X_test = pd.read_csv("methylation_X_test_data.csv")
        y_test = pd.read_csv("methylation_y_test_data.csv")['Cancer']
        X_train = pd.read_csv("methylation_X_train_data.csv")
        y_train = pd.read_csv("methylation_y_train_data.csv")['Cancer']

        # Feature selection
        selector = SelectKBest(score_func=mutual_info_classif, k=100)  # k=50 → k=100
        selector.fit(X_train, y_train)
        selected_features = X_train.columns[selector.get_support()]
        X_train = pd.DataFrame(selector.transform(X_train), columns=selected_features)
        X_test = X_test[selected_features]

    elif model_type == 'protein':
        model = joblib.load("pro_MLPClassifier_best_model.pkl")
        X_test = pd.read_csv("protein_X_test.csv")
        y_test = pd.read_csv("protein_y_test.csv")['Cancer']
        X_train = pd.read_csv("protein_X_train.csv")
        y_train = pd.read_csv("protein_y_train.csv")['Cancer']

        # Feature selection (t-test)
        p_values = []
        for col in X_train.columns:
            t_stat, p_val = ttest_ind(X_train.loc[y_train == 1, col], X_train.loc[y_train == 0, col], equal_var=False, nan_policy='omit')
            p_values.append(p_val)

        reject, pvals_corrected, _, _ = multipletests(p_values, method='fdr_bh')
        ttest_results = pd.DataFrame({'feature': X_train.columns, 'p_value': p_values, 'p_value_corrected': pvals_corrected})

        # 선택된 feature 저장 후 동일하게 적용 (p-value 기준 완화)
        selected_features = ttest_results[ttest_results['p_value_corrected'] < 0.1]['feature'].tolist()  # 0.05 → 0.1
        X_train = X_train[selected_features]
        X_test = X_test[selected_features]

    else:
        raise ValueError("Invalid model_type. Choose from 'cnn', 'methylation', 'protein'")

    return model, X_test, y_test, X_train, y_train

# 2. 앙상블 함수 (가중치 조정)
def weighted_average_ensemble(predictions, f1_scores):
    total_f1 = sum(f1_scores.values())
    weights = {model: (f1 / total_f1) ** 0.5 for model, f1 in f1_scores.items()}  # ** 0.5 로 가중치 완화

    # 모든 모델 예측 결과 크기 통일
    common_length = min(len(pred) for pred in predictions.values())
    predictions = {model: pred[:common_length] for model, pred in predictions.items()}

    ensemble_proba = np.sum([predictions[model] * weights[model] for model in predictions], axis=0)
    return ensemble_proba

# 3. 모델 및 F1-score 정보
model_paths = {
    'cnn': "cnn-k-NN_best_model.pkl",
    'methylation': "methyl_SVM_best_model.pkl",
    'protein': "pro_MLPClassifier_best_model.pkl"
}

f1_scores = {
    'cnn': 0.98,
    'methylation': 0.98,
    'protein': 0.93
}

# 4. 앙상블 및 평가
predictions = {}
_, _, y_test, X_train, y_train = load_model_and_data('cnn')

# ✅ 데이터 불균형 해결 (SMOTE 적용)
smote = SMOTE(sampling_strategy='auto', random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

for model_name in model_paths:
    model, X_test, _, _, _ = load_model_and_data(model_name)

    # Feature mismatch 해결
    model_features = model.feature_names_in_
    X_test = X_test.reindex(columns=model_features, fill_value=0)

    # 모델 예측
    if hasattr(model, "predict_proba"):
        predictions[model_name] = model.predict_proba(X_test)[:, 1]
    else:
        decision_values = model.decision_function(X_test)
        predictions[model_name] = 1 / (1 + np.exp(-decision_values))

ensemble_predictions = weighted_average_ensemble(predictions, f1_scores)

# ✅ 최적 threshold 찾기
precision, recall, thresholds = precision_recall_curve(y_test[:len(ensemble_predictions)], ensemble_predictions)
f1_scores = (2 * precision * recall) / (precision + recall)
best_threshold = thresholds[np.argmax(f1_scores)]  # F1-score가 가장 높은 threshold 선택

ensemble_classes = (ensemble_predictions >= best_threshold).astype(int)
print(f"Best threshold: {best_threshold}")

# ✅ 최종 결과
print("\nEnsemble Performance:")
print(classification_report(y_test[:len(ensemble_classes)], ensemble_classes))
print(confusion_matrix(y_test[:len(ensemble_classes)], ensemble_classes))
print(f"F1-score: {f1_score(y_test[:len(ensemble_classes)], ensemble_classes):.4f}")
print(f"ROC AUC: {roc_auc_score(y_test[:len(ensemble_classes)], ensemble_predictions):.4f}")
print(f"Average Precision: {average_precision_score(y_test[:len(ensemble_classes)], ensemble_predictions):.4f}")

# 6. ROC, PR 곡선
fpr, tpr, _ = roc_curve(y_test[:len(ensemble_predictions)], ensemble_predictions)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Ensemble ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (Ensemble)')
plt.legend(loc="lower right")

precision, recall, _ = precision_recall_curve(y_test[:len(ensemble_predictions)], ensemble_predictions)
average_precision = average_precision_score(y_test[:len(ensemble_predictions)], ensemble_predictions)

plt.subplot(1, 2, 2)
plt.plot(recall, precision, color='blue', lw=2, label=f'Ensemble PR curve (AP = {average_precision:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve (Ensemble)')
plt.legend(loc="lower left")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    accuracy_score, f1_score, confusion_matrix, classification_report,
    roc_auc_score, average_precision_score, roc_curve, auc, precision_recall_curve
)
from sklearn.feature_selection import SelectKBest, mutual_info_classif
from scipy.stats import ttest_ind
from statsmodels.stats.multitest import multipletests
from imblearn.over_sampling import SMOTE

# 1. 모델 및 데이터 로드 함수 (feature selection 포함)
def load_model_and_data(model_type):
    selected_features = None  # 기본값 설정

    if model_type == 'cnn':
        model = joblib.load("cnn-k-NN_best_model.pkl")
        X_test = joblib.load("cnn_X_test.pkl")
        y_test = joblib.load("cnn_y_test.pkl")
        X_train = joblib.load("cnn_X_train.pkl")
        y_train = joblib.load("cnn_y_train.pkl")

        selected_features = X_train.columns  # 모든 feature 사용

    elif model_type == 'methylation':
        model = joblib.load("methyl_SVM_best_model.pkl")
        X_test = pd.read_csv("methylation_X_test_data.csv")
        y_test = pd.read_csv("methylation_y_test_data.csv")['Cancer']
        X_train = pd.read_csv("methylation_X_train_data.csv")
        y_train = pd.read_csv("methylation_y_train_data.csv")['Cancer']

        # Feature selection
        selector = SelectKBest(score_func=mutual_info_classif, k=min(100, X_train.shape[1]))
        selector.fit(X_train, y_train)
        selected_features = X_train.columns[selector.get_support()]
        X_train = pd.DataFrame(selector.transform(X_train), columns=selected_features)
        X_test = X_test[selected_features]

    elif model_type == 'protein':
        model = joblib.load("pro_MLPClassifier_best_model.pkl")
        X_test = pd.read_csv("protein_X_test.csv")
        y_test = pd.read_csv("protein_y_test.csv")['Cancer']
        X_train = pd.read_csv("protein_X_train.csv")
        y_train = pd.read_csv("protein_y_train.csv")['Cancer']

        # Feature selection (t-test)
        p_values = []
        for col in X_train.columns:
            t_stat, p_val = ttest_ind(X_train.loc[y_train == 1, col], X_train.loc[y_train == 0, col], equal_var=False, nan_policy='omit')
            p_values.append(p_val)

        reject, pvals_corrected, _, _ = multipletests(p_values, method='fdr_bh')
        ttest_results = pd.DataFrame({'feature': X_train.columns, 'p_value': p_values, 'p_value_corrected': pvals_corrected})

        # 선택된 feature 저장 후 동일하게 적용
        selected_features = ttest_results[ttest_results['p_value_corrected'] < 0.1]['feature'].tolist()
        X_train = X_train[selected_features]
        X_test = X_test[selected_features]

    #elif model_type == 'gene_expression':
     #   model = joblib.load("gene_ex_logistic_regression_model.pkl")
      #  X_test = pd.read_csv("gene_expression_X_test.csv")
      #  y_test = pd.read_csv("gene_expression_y_test.csv")['Cancer']
      #  X_train = pd.read_csv("gene_expression_X_train.csv")
      #  y_train = pd.read_csv("gene_expression_y_train.csv")['Cancer']

        # Feature selection
      #  selector = SelectKBest(score_func=mutual_info_classif, k=min(100, X_train.shape[1]))
      #  selector.fit(X_train, y_train)
      #  selected_features = X_train.columns[selector.get_support()]
      #  X_train = pd.DataFrame(selector.transform(X_train), columns=selected_features)
      #  X_test = X_test[selected_features]

    else:
        raise ValueError("Invalid model_type. Choose from 'cnn', 'methylation', 'protein'")  #, 'gene_expression'

    return model, X_test, y_test, X_train, y_train, selected_features

# 2. 데이터 불균형 해결 (SMOTE 적용 후 모델 재학습)
_, _, y_test, X_train, y_train, selected_features = load_model_and_data('cnn')

# ✅ SMOTE 적용 (Feature selection 후)
smote = SMOTE(sampling_strategy='auto', random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# ✅ SMOTE 적용 후 선택된 feature 유지
X_train_resampled = pd.DataFrame(X_train_resampled, columns=selected_features)

# ✅ F1-score 값 (앙상블 가중치 계산용)
f1_scores = {
    'cnn': 0.98,
    'methylation': 0.98,
    'protein': 0.93,
    #'gene_expression': 0.90
}


# 앙상블 함수 (가중치 조정)
def weighted_average_ensemble(predictions, f1_scores):
    total_f1 = sum(f1_scores.values())
    weights = {model: (f1 / total_f1) ** 0.5 for model, f1 in f1_scores.items()}  # ** 0.5 로 가중치 완화

    # 모든 모델 예측 결과 크기 통일
    common_length = min(len(pred) for pred in predictions.values())
    predictions = {model: pred[:common_length] for model, pred in predictions.items()}

    ensemble_proba = np.sum([predictions[model] * weights[model] for model in predictions], axis=0)
    return ensemble_proba

# 3. 모델 예측 및 평가
predictions = {}
for model_name in f1_scores.keys():
    model, X_test, _, _, _, _ = load_model_and_data(model_name)

    # ✅ Feature mismatch 해결
    X_test = X_test.reindex(columns=selected_features, fill_value=0)

    # 모델 재학습
    model.fit(X_train_resampled, y_train_resampled)

    # 모델 예측
    if hasattr(model, "predict_proba"):
        predictions[model_name] = model.predict_proba(X_test)[:, 1]
    else:
        decision_values = model.decision_function(X_test)
        predictions[model_name] = 1 / (1 + np.exp(-decision_values))

# ✅ 앙상블 예측
ensemble_predictions = weighted_average_ensemble(predictions, f1_scores)

# ✅ 최적 threshold 찾기
precision, recall, thresholds = precision_recall_curve(y_test[:len(ensemble_predictions)], ensemble_predictions)
f1_scores_array = (2 * precision * recall) / (precision + recall)
best_threshold = thresholds[np.argmax(f1_scores_array)]

# ✅ 최종 평가
ensemble_classes = (ensemble_predictions >= best_threshold).astype(int)
print(f"Best threshold: {best_threshold}")
print("\nEnsemble Performance:")
print(classification_report(y_test[:len(ensemble_classes)], ensemble_classes))

# ✅ ROC AUC 확인
print(f"ROC AUC: {roc_auc_score(y_test[:len(ensemble_classes)], ensemble_predictions):.4f}")

# ✅ 모델 저장
joblib.dump(predictions, "ensemble_model_with_gene_expression.pkl")
np.save("ensemble_predictions_with_gene_expression.npy", ensemble_predictions)
print("✅ 앙상블 모델 및 예측 결과 저장 완료!")

# 6. ROC, PR 곡선
fpr, tpr, _ = roc_curve(y_test[:len(ensemble_predictions)], ensemble_predictions)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Ensemble ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (Ensemble)')
plt.legend(loc="lower right")

precision, recall, _ = precision_recall_curve(y_test[:len(ensemble_predictions)], ensemble_predictions)
average_precision = average_precision_score(y_test[:len(ensemble_predictions)], ensemble_predictions)

plt.subplot(1, 2, 2)
plt.plot(recall, precision, color='blue', lw=2, label=f'Ensemble PR curve (AP = {average_precision:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve (Ensemble)')
plt.legend(loc="lower left")
plt.tight_layout()
plt.show()